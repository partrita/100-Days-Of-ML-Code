# 100일간의 머신러닝 코드

[Siraj Raval](https://github.com/llSourcell)이 제안한 100일간의 머신러닝 코딩

[여기](https://github.com/Avik-Jain/100-Days-Of-ML-Code/tree/master/datasets)에서 데이터셋을 받으세요.

## 데이터 전처리 | 1일차
[여기](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%201_Data%20PreProcessing.md)에서 코드를 확인하세요.

<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%201.jpg">
</p>

## 단순 선형 회귀 | 2일차
[여기](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day2_Simple_Linear_Regression.md)에서 코드를 확인하세요.

<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%202.jpg">
</p>

## 다중 선형 회귀 | 3일차
[여기](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day3_Multiple_Linear_Regression.md)에서 코드를 확인하세요.

<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%203.jpg">
</p>

## 로지스틱 회귀 | 4일차

<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%204.jpg">
</p>

## 로지스틱 회귀 | 5일차
#100DaysOfMLCode를 진행하면서 오늘 로지스틱 회귀가 실제로 무엇이며 그 뒤에 숨겨진 수학은 무엇인지 더 깊이 파고들었습니다. 비용 함수가 어떻게 계산되는지, 그리고 예측 오류를 최소화하기 위해 비용 함수에 경사 하강 알고리즘을 적용하는 방법을 배웠습니다.
시간이 부족하여 이제 격일로 인포그래픽을 게시할 예정입니다.
또한 코드 문서화에 도움을 주실 분이 있고 이미 해당 분야에 경험이 있으며 github용 Markdown을 알고 계신다면 LinkedIn으로 저에게 연락해 주세요 :).

## 로지스틱 회귀 구현 | 6일차
[여기](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%206%20Logistic%20Regression.md)에서 코드를 확인하세요.

## K 최근접 이웃 | 7일차
<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%207.jpg">
</p>

## 로지스틱 회귀의 수학적 원리 | 8일차

#100DaysOfMLCode 로지스틱 회귀에 대한 이해를 명확히 하기 위해 인터넷에서 자료나 기사를 검색하다가 Saishruthi Swaminathan의 이 기사(https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)를 발견했습니다.

로지스틱 회귀에 대한 자세한 설명을 제공합니다. 확인해 보세요.

## 서포트 벡터 머신 | 9일차
SVM이 무엇이며 분류 문제를 해결하는 데 어떻게 사용되는지에 대한 직관을 얻었습니다.

## SVM 및 KNN | 10일차
SVM 작동 방식에 대해 더 자세히 배우고 K-NN 알고리즘을 구현했습니다.

## K-NN 구현 | 11일차

분류를 위한 K-NN 알고리즘을 구현했습니다. #100DaysOfMLCode
서포트 벡터 머신 인포그래픽이 절반 정도 완료되었습니다. 내일 업데이트하겠습니다.

## 서포트 벡터 머신 | 12일차
<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2012.jpg">
</p>

## 나이브 베이즈 분류기 | 13일차

#100DaysOfMLCode를 계속 진행하면서 오늘 나이브 베이즈 분류기를 살펴보았습니다.
또한 scikit-learn을 사용하여 파이썬으로 SVM을 구현하고 있습니다. 코드는 곧 업데이트하겠습니다.

## SVM 구현 | 14일차
오늘 선형적으로 관련된 데이터에 SVM을 구현했습니다. Scikit-Learn 라이브러리를 사용했습니다. Scikit-Learn에는 이 작업을 수행하는 데 사용하는 SVC 분류기가 있습니다. 다음 구현에서는 커널 트릭을 사용할 예정입니다.
[여기](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2013%20SVM.md)에서 코드를 확인하세요.

## 나이브 베이즈 분류기 및 블랙박스 머신러닝 | 15일차
다양한 유형의 나이브 베이즈 분류기에 대해 배웠습니다. 또한 [Bloomberg](https://bloomberg.github.io/foml/#home)의 강의를 듣기 시작했습니다. 재생 목록의 첫 번째 강의는 블랙박스 머신러닝이었습니다. 예측 함수, 특징 추출, 학습 알고리즘, 성능 평가, 교차 검증, 샘플 편향, 비정상성, 과적합 및 하이퍼파라미터 튜닝에 대한 전체 개요를 제공합니다.

## 커널 트릭을 사용한 SVM 구현 | 16일차
Scikit-Learn 라이브러리를 사용하여 데이터 포인트를 더 높은 차원으로 매핑하여 최적의 초평면을 찾는 커널 함수와 함께 SVM 알고리즘을 구현했습니다.

## Coursera에서 딥러닝 전문 과정 시작 | 17일차
하루 만에 1주차와 2주차 전체를 완료했습니다. 신경망으로서의 로지스틱 회귀를 배웠습니다.

## Coursera에서 딥러닝 전문 과정 | 18일차
딥러닝 전문 과정의 첫 번째 과정을 완료했습니다. 파이썬으로 신경망을 구현했습니다.

## 학습 문제, Yaser Abu-Mostafa 교수 | 19일차
Yaser Abu-Mostafa 교수의 Caltech 머신러닝 과정(CS 156) 18개 강의 중 첫 번째 강의를 시작했습니다. 기본적으로 다음 강의에 대한 소개였습니다. 또한 퍼셉트론 알고리즘에 대해서도 설명했습니다.

## 딥러닝 전문 과정 2 시작 | 20일차
심층 신경망 개선: 하이퍼파라미터 튜닝, 정규화 및 최적화 1주차를 완료했습니다.

## 웹 스크래핑 | 21일차
모델 구축을 위한 데이터 수집을 위해 Beautiful Soup을 사용하여 웹 스크래핑을 수행하는 방법에 대한 몇 가지 튜토리얼을 시청했습니다.

## 학습은 가능한가? | 22일차
Yaser Abu-Mostafa 교수의 Caltech 머신러닝 과정(CS 156) 18개 강의 중 두 번째 강의. 호프딩 부등식에 대해 배웠습니다.

## 결정 트리 | 23일차
<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2023.jpg">
</p>

## 통계 학습 이론 소개 | 24일차
Bloomberg ML 과정의 세 번째 강의에서는 입력 공간, 행동 공간, 결과 공간, 예측 함수, 손실 함수 및 가설 공간과 같은 핵심 개념 중 일부를 소개했습니다.

## 결정 트리 구현 | 25일차
[여기](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2025%20Decision%20Tree.md)에서 코드를 확인하세요.

## 선형 대수 복습으로 이동 | 26일차
유튜브에서 3Blue1Brown이라는 놀라운 [채널](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw)을 발견했습니다. 선형 대수의 본질이라는 재생 목록이 있습니다. 벡터, 선형 조합, 스팬, 기저 벡터, 선형 변환 및 행렬 곱셈에 대한 전체 개요를 제공하는 4개의 비디오를 완료하며 시작했습니다.

재생 목록 링크는 [여기](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)입니다.

## 선형 대수 복습으로 이동 | 27일차
재생 목록을 계속 진행하면서 3D 변환, 행렬식, 역행렬, 열 공간, 영 공간 및 비정방 행렬 주제를 다루는 다음 4개의 비디오를 완료했습니다.

재생 목록 링크는 [여기](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)입니다.

## 선형 대수 복습으로 이동 | 28일차
3Blue1Brown의 재생 목록에서 선형 대수의 본질에서 3개의 비디오를 추가로 완료했습니다.
다룬 주제는 내적과 외적이었습니다.

재생 목록 링크는 [여기](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)입니다.


## 선형 대수 복습으로 이동 | 29일차
오늘 12-14번 비디오를 통해 전체 재생 목록을 완료했습니다. 선형 대수 개념을 복습하기에 정말 놀라운 재생 목록입니다.
다룬 주제는 기저 변경, 고유 벡터 및 고유값, 추상 벡터 공간이었습니다.

재생 목록 링크는 [여기](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)입니다.

## 미적분학의 본질 | 30일차
3blue1brown의 선형 대수의 본질 재생 목록을 완료하자 유튜브에서 같은 채널 3Blue1Brown의 비디오 시리즈에 대한 제안이 나타났습니다. 이미 이전 선형 대수 시리즈에 깊은 인상을 받았기 때문에 바로 뛰어들었습니다.
도함수, 연쇄 법칙, 곱셈 법칙 및 지수 함수의 도함수와 같은 주제에 대한 약 5개의 비디오를 완료했습니다.

재생 목록 링크는 [여기](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)입니다.

## 미적분학의 본질 | 31일차
미적분학의 본질 재생 목록에서 음함수 미분 및 극한 주제에 대한 2개의 비디오를 시청했습니다.

재생 목록 링크는 [여기](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)입니다.

## 미적분학의 본질 | 32일차
적분 및 고계 도함수와 같은 주제를 다루는 나머지 4개의 비디오를 시청했습니다.

재생 목록 링크는 [여기](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)입니다.

## 랜덤 포레스트 | 33일차
<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2033.jpg">
</p>

## 랜덤 포레스트 구현 | 34일차
[여기](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2034%20Random_Forest.md)에서 코드를 확인하세요.

## 하지만 신경망이란 *무엇*일까요? | 딥러닝, 1장 | 35일차
3Blue1Brown 유튜브 채널의 신경망에 대한 놀라운 비디오. 이 비디오는 신경망에 대한 이해를 돕고 손으로 쓴 숫자 데이터셋을 사용하여 개념을 설명합니다.
[비디오](https://www.youtube.com/watch?v=aircAruvnKk&t=7s) 링크입니다.

## 경사 하강, 신경망이 학습하는 방법 | 딥러닝, 2장 | 36일차
3Blue1Brown 유튜브 채널의 신경망 2부. 이 비디오는 흥미로운 방식으로 경사 하강 개념을 설명합니다. 169 꼭 봐야 할 강력 추천 비디오입니다.
[비디오](https://www.youtube.com/watch?v=IHZwWFHWa-w) 링크입니다.

## 역전파는 실제로 무엇을 하고 있을까요? | 딥러닝, 3장 | 37일차
3Blue1Brown 유튜브 채널의 신경망 3부. 이 비디오는 주로 편도함수와 역전파에 대해 설명합니다.
[비디오](https://www.youtube.com/watch?v=Ilg3gGewQ5U) 링크입니다.

## 역전파 미적분학 | 딥러닝, 4장 | 38일차
3Blue1Brown 유튜브 채널의 신경망 4부. 여기서 목표는 역전파가 작동하는 방식에 대한 직관을 다소 공식적인 용어로 표현하는 것이며 비디오는 주로 편도함수와 역전파에 대해 설명합니다.
[비디오](https://www.youtube.com/watch?v=tIeHLnjs5U8) 링크입니다.

## 파이썬, 텐서플로우, 케라스를 사용한 딥러닝 튜토리얼 | 39일차
[비디오](https://www.youtube.com/watch?v=wQ8BIBpya2k&t=19s&index=2&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN) 링크입니다.

## 자체 데이터 로드 - 파이썬, 텐서플로우, 케라스를 사용한 딥러닝 기초 2부 | 40일차
[비디오](https://www.youtube.com/watch?v=j-3vuBynnOE&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&index=2) 링크입니다.

## 컨볼루션 신경망 - 파이썬, 텐서플로우, 케라스를 사용한 딥러닝 기초 3부 | 41일차
[비디오](https://www.youtube.com/watch?v=WvoLTXIjBYU&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&index=3) 링크입니다.

## 텐서보드를 사용한 모델 분석 - 파이썬, 텐서플로우, 케라스를 사용한 딥러닝 4부 | 42일차
[비디오](https://www.youtube.com/watch?v=BqgTU7_cBnk&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&index=4) 링크입니다.

## K 평균 군집화 | 43일차
비지도 학습으로 넘어가 군집화에 대해 공부했습니다.
제 웹사이트 [avikjain.me](http://www.avikjain.me/)를 확인해 보세요.
또한 K 평균 군집화를 쉽게 이해하는 데 도움이 되는 멋진 애니메이션을 찾았습니다. [링크](http://shabal.in/visuals/kmeans/6.html)

<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2043.jpg">
</p>

## K 평균 군집화 구현 | 44일차
K 평균 군집화를 구현했습니다. [여기]()에서 코드를 확인하세요.

## 더 깊이 파고들기 | NUMPY | 45일차
JK VanderPlas의 새 책 "Python Data Science HandBook"을 받았습니다. [여기](https://github.com/jakevdp/PythonDataScienceHandbook)에서 Jupyter 노트북을 확인하세요.
<br>2장 Numpy 소개부터 시작했습니다. 데이터 유형, Numpy 배열 및 Numpy 배열 연산과 같은 주제를 다루었습니다.
<br>코드를 확인하세요 -
<br>[NumPy 소개](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.00-Introduction-to-NumPy.ipynb)
<br>[파이썬의 데이터 유형 이해](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.01-Understanding-Data-Types.ipynb)
<br>[NumPy 배열의 기초](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.02-The-Basics-Of-NumPy-Arrays.ipynb)
<br>[NumPy 배열 연산: 유니버설 함수](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.03-Computation-on-arrays-ufuncs.ipynb)

## 더 깊이 파고들기 | NUMPY | 46일차
2장: 집계, 비교 및 브로드캐스팅
<br>노트북 링크:
<br>[집계: 최소, 최대 및 그 사이의 모든 것](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.04-Computation-on-arrays-aggregates.ipynb)
<br>[배열 연산: 브로드캐스팅](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.05-Computation-on-arrays-broadcasting.ipynb)
<br>[비교, 마스크 및 부울 논리](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.06-Boolean-Arrays-and-Masks.ipynb)

## 더 깊이 파고들기 | NUMPY | 47일차
2장: 팬시 인덱싱, 배열 정렬, 구조화된 데이터
<br>노트북 링크:
<br>[팬시 인덱싱](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.07-Fancy-Indexing.ipynb)
<br>[배열 정렬](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.08-Sorting.ipynb)
<br>[구조화된 데이터: NumPy의 구조화된 배열](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.09-<br>Structured-Data-NumPy.ipynb)

## 더 깊이 파고들기 | PANDAS | 48일차
3장: Pandas를 사용한 데이터 조작
<br> Pandas 객체, 데이터 인덱싱 및 선택, 데이터 연산, 누락된 데이터 처리, 계층적 인덱싱, ConCat 및 Append와 같은 다양한 주제를 다루었습니다.
<br>노트북 링크:
<br>[Pandas를 사용한 데이터 조작](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.00-Introduction-to-Pandas.ipynb)
<br>[Pandas 객체 소개](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.01-Introducing-Pandas-Objects.ipynb)
<br>[데이터 인덱싱 및 선택](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.02-Data-Indexing-and-Selection.ipynb)
<br>[Pandas의 데이터 연산](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.03-Operations-in-Pandas.ipynb)
<br>[누락된 데이터 처리](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.04-Missing-Values.ipynb)
<br>[계층적 인덱싱](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.05-Hierarchical-Indexing.ipynb)
<br>[데이터셋 결합: Concat 및 Append](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.06-Concat-And-Append.ipynb)

## 더 깊이 파고들기 | PANDAS | 49일차
3장: 다음 주제 완료 - 병합 및 조인, 집계 및 그룹화, 피벗 테이블.
<br>[데이터셋 결합: 병합 및 조인](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.07-Merge-and-Join.ipynb)
<br>[집계 및 그룹화](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb)
<br>[피벗 테이블](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.09-Pivot-Tables.ipynb)

## 더 깊이 파고들기 | PANDAS | 50일차
3장: 벡터화된 문자열 연산, 시계열 작업
<br>노트북 링크:
<br>[벡터화된 문자열 연산](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.10-Working-With-Strings.ipynb)
<br>[시계열 작업](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.11-Working-with-Time-Series.ipynb)
<br>[고성능 Pandas: eval() 및 query()](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.12-Performance-Eval-and-Query.ipynb)

## 더 깊이 파고들기 | MATPLOTLIB | 51일차
4장: Matplotlib을 사용한 시각화
단순 선 플롯, 단순 산점도, 밀도 및 등고선 플롯에 대해 배웠습니다.
<br>노트북 링크:
<br>[Matplotlib을 사용한 시각화](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.00-Introduction-To-Matplotlib.ipynb)
<br>[단순 선 플롯](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.01-Simple-Line-Plots.ipynb)
<br>[단순 산점도](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.02-Simple-Scatter-Plots.ipynb)
<br>[오류 시각화](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.03-Errorbars.ipynb)
<br>[밀도 및 등고선 플롯](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.04-Density-and-Contour-Plots.ipynb)

## 더 깊이 파고들기 | MATPLOTLIB | 52일차
4장: Matplotlib을 사용한 시각화
히스토그램, 플롯 범례 사용자 지정 방법, 색상 막대 및 다중 서브플롯 만들기에 대해 배웠습니다.
<br>노트북 링크:
<br>[히스토그램, 구간화 및 밀도](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.05-Histograms-and-Binnings.ipynb)
<br>[플롯 범례 사용자 지정](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.06-Customizing-Legends.ipynb)
<br>[색상 막대 사용자 지정](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.07-Customizing-Colorbars.ipynb)
<br>[다중 서브플롯](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.08-Multiple-Subplots.ipynb)
<br>[텍스트 및 주석](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.09-Text-and-Annotation.ipynb)

## 더 깊이 파고들기 | MATPLOTLIB | 53일차
4장: Mathplotlib의 3차원 플로팅을 다루었습니다.
<br>노트북 링크:
<br>[Matplotlib의 3차원 플로팅](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.12-Three-Dimensional-Plotting.ipynb)

## 계층적 군집화 | 54일차
계층적 군집화에 대해 공부했습니다.
이 놀라운 [시각화](https://cdn-images-1.medium.com/max/800/1*ET8kCcPpr893vNZFs8j4xg.gif)를 확인해 보세요.
<p align="center">
  <img src="https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2054.jpg">
</p>
