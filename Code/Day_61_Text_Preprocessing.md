# Day 61: 텍스트 전처리 (Text Preprocessing)

## 학습 목표
- 텍스트 전처리의 중요성과 목적 이해
- 주요 텍스트 전처리 기법 학습:
    - 문장 분리 (Sentence Segmentation)
    - 토큰화 (Tokenization)
    - 정제 (Cleaning) 및 정규화 (Normalization)
    - 불용어 제거 (Stopword Removal)
    - 어간 추출 (Stemming)
    - 표제어 추출 (Lemmatization)

## 1. 텍스트 전처리란?
- 자연어 텍스트를 분석 가능한 형태로 가공하고 정제하는 일련의 과정입니다.
- 목적:
    - 분석의 정확도 향상
    - 계산 효율성 증대
    - 데이터의 일관성 유지
    - 노이즈 제거

## 2. 주요 텍스트 전처리 기법

### 가. 문장 분리 (Sentence Segmentation / Sentence Tokenization)
- 텍스트를 개별 문장 단위로 분리하는 작업입니다.
- 문장 부호(마침표(.), 물음표(?), 느낌표(!)) 등을 기준으로 분리하지만, 예외 케이스(Dr., Mr., Ph.D. 등)를 고려해야 합니다.
- 파이썬 라이브러리: `NLTK`의 `sent_tokenize`

### 나. 토큰화 (Tokenization / Word Tokenization)
- 문장을 의미 있는 최소 단위인 토큰(주로 단어)으로 분리하는 작업입니다.
- 공백, 문장 부호 등을 기준으로 분리할 수 있습니다.
- 어절 단위 토큰화, 단어 단위 토큰화, 형태소 단위 토큰화 등 다양한 수준이 있습니다.
- 파이썬 라이브러리: `NLTK`의 `word_tokenize`, `spaCy`, 한국어의 경우 `KoNLPy` (Okt, Mecab 등)

### 다. 정제 (Cleaning) 및 정규화 (Normalization)
- 텍스트에서 불필요하거나 분석에 방해가 되는 요소를 제거하고, 표현을 통일하는 과정입니다.
- **정제 (Cleaning)**:
    - HTML 태그 제거 (예: 웹 크롤링 데이터)
    - 특수 문자, 숫자, 이모티콘 등 제거 또는 대체
    - 오타 수정
- **정규화 (Normalization)**:
    - 대소문자 통일 (주로 소문자로 변환)
    - 축약형 풀기 (예: "don't" -> "do not")
    - 철자 변이 통일 (예: "color", "colour" -> "color")
    - 숫자 표현 통일 (예: "1,000", "one thousand" -> "1000")

### 라. 불용어 제거 (Stopword Removal)
- 분석에 큰 의미가 없으면서 자주 등장하는 단어(불용어)를 제거하는 작업입니다.
- 예: "a", "an", "the", "is", "are", "of", "on", "in" (영어) / "은", "는", "이", "가", "을", "를" (한국어)
- 불용어 목록은 직접 정의하거나 라이브러리에서 제공하는 것을 사용할 수 있습니다.
- 파이썬 라이브러리: `NLTK`의 `stopwords`

### 마. 어간 추출 (Stemming)
- 단어의 어미(접미사)를 제거하여 어간(stem)만을 추출하는 과정입니다.
- 목적: 단어의 다양한 활용형을 동일한 형태로 통일하여 단어의 수를 줄이고 분석의 일관성을 높입니다.
- 규칙 기반으로 작동하며, 때로는 문법적으로 정확하지 않은 어간을 추출할 수 있습니다 (예: "running" -> "runn", "flies" -> "fli").
- 속도가 빠르다는 장점이 있습니다.
- 대표적인 알고리즘: 포터 스테머(Porter Stemmer), 랭커스터 스테머(Lancaster Stemmer)
- 파이썬 라이브러리: `NLTK`의 `PorterStemmer`, `LancasterStemmer`

### 바. 표제어 추출 (Lemmatization)
- 단어의 기본형, 즉 표제어(lemma)를 추출하는 과정입니다.
- 품사 정보와 문맥을 고려하여 단어의 사전적 기본형을 찾습니다. (예: "running" -> "run", "flies" -> "fly", "better" -> "good")
- 어간 추출보다 문법적으로 정확한 결과를 제공하지만, 더 복잡하고 시간이 오래 걸릴 수 있습니다.
- 일반적으로 어간 추출보다 선호되나, 분석 목적과 성능 요구사항에 따라 선택합니다.
- 파이썬 라이브러리: `NLTK`의 `WordNetLemmatizer`, `spaCy`

## 3. 한국어 텍스트 전처리 특수성
- **형태소 분석의 중요성**: 한국어는 교착어로, 어근에 접사가 붙어 단어의 의미와 문법적 기능이 결정됩니다. 따라서 단순 공백 토큰화보다는 형태소 분석기를 사용하여 명사, 동사, 형용사 등을 추출하는 것이 효과적입니다. (KoNLPy 라이브러리 활용)
- **띄어쓰기 오류**: 한국어는 띄어쓰기가 틀려도 의미 전달이 되는 경우가 많아, 띄어쓰기 교정 작업이 필요할 수 있습니다.
- **다양한 어미 활용**: 동사나 형용사의 활용형이 매우 다양하여 어간 추출이나 표제어 추출의 중요성이 큽니다.

## 4. 전처리 파이프라인 예시
1. 텍스트 로드
2. (선택적) 소문자화
3. 문장 분리
4. 각 문장에 대해:
    a. 토큰화 (단어 또는 형태소)
    b. (선택적) 정제 (특수문자 제거 등)
    c. (선택적) 불용어 제거
    d. 어간 추출 또는 표제어 추출
5. 전처리된 토큰 리스트 생성

## 추가 학습 자료
- [NLTK Book - Chapter 3: Processing Raw Text](https://www.nltk.org/book/ch03.html)
- [KoNLPy 공식 문서](https://konlpy.org/ko/latest/)
- [딥 러닝을 이용한 자연어 처리 입문 - 텍스트 전처리](https://wikidocs.net/21698)

## 다음 학습 내용
- Day 62: Bag-of-Words 및 TF-IDF (Bag-of-Words and TF-IDF)
